{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Pytorch implementation"
      ],
      "metadata": {
        "id": "MvuLgysppc41"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "99DdtN3fpUh4",
        "outputId": "59948a63-ceb0-430a-ae13-b0019a324ff4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m38.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m78.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ],
      "source": [
        "!pip install numpy torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "M-qT_xKLpamT"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vrns6-mBpapN"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tensors\n",
        "\n",
        "At its core, Pytorch is a library for processing tensors. A tensor is a number, vector, matrix or any n-dimensional array.\n"
      ],
      "metadata": {
        "id": "4aQTqYSIuQww"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's create tensor with a single number\n",
        "t1 = torch.tensor(4.8)\n",
        "t1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OqxZCwMipasZ",
        "outputId": "51d25a61-0604-4143-b524-565438ee989a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(4.8000)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Vector tensor - 1D\n",
        "\n",
        "t2 = torch.tensor([1,2,3,4,5.])\n",
        "t2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jWFALSl9pavn",
        "outputId": "14be70a2-2d00-47e7-d2e5-a4aab973c9a0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 2., 3., 4., 5.])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Matrix - 2D\n",
        "\n",
        "t3 = torch.tensor([ [1,2,3,100], [4,5,6,200], [7,8,9,300] ])\n",
        "t3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5XIuJCZopayW",
        "outputId": "3bac8ea6-3721-41c1-ddaa-d2b028576352"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  1,   2,   3, 100],\n",
              "        [  4,   5,   6, 200],\n",
              "        [  7,   8,   9, 300]])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Matrix - 3D\n",
        "\n",
        "t4 = torch.tensor([\n",
        "    [\n",
        "       [1,2,100],\n",
        "       [3,4,200],\n",
        "    ],\n",
        "    [\n",
        "        [5,6,1000],\n",
        "        [7,8,2000],\n",
        "    ]\n",
        "])\n",
        "t4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PJRWn184pa1h",
        "outputId": "8163e4a8-ad4e-438a-aeff-30bcabae4d1a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[   1,    2,  100],\n",
              "         [   3,    4,  200]],\n",
              "\n",
              "        [[   5,    6, 1000],\n",
              "         [   7,    8, 2000]]])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6sZPG5y3pa4d"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NOTE:** Tensors can have any number of dimensions and different lenghts along each dimension.\n",
        "\n",
        "We can inspect the lenght along each dimension using the ```.shape``` property of tensor."
      ],
      "metadata": {
        "id": "zjmR60iU8XSv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(t1)\n",
        "print(\"\\nt1 shape:\", t1.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VfdjxVW4pa7k",
        "outputId": "31c48cd9-c963-4e78-8ff1-1eb0385e9d9e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(4.8000)\n",
            "\n",
            "t1 shape: torch.Size([])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(t2)\n",
        "t2.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FCJ9wiXMpa-E",
        "outputId": "60634865-75f8-4bdc-b789-1da478c6fd51"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1., 2., 3., 4., 5.])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([5])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(t3)\n",
        "t3.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Vi2AqvipbBK",
        "outputId": "43d4e544-aa46-4cfc-d120-779f2981e28b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[  1,   2,   3, 100],\n",
            "        [  4,   5,   6, 200],\n",
            "        [  7,   8,   9, 300]])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(t4)\n",
        "t4.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7nV7Ltt6pbDp",
        "outputId": "85f3ba45-d828-4c5f-e235-1181065f8517"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[   1,    2,  100],\n",
            "         [   3,    4,  200]],\n",
            "\n",
            "        [[   5,    6, 1000],\n",
            "         [   7,    8, 2000]]])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Matrix - 3D but improper\n",
        "\n",
        "t5 = torch.tensor([\n",
        "    [\n",
        "       [1,2],\n",
        "       [3,4,200],\n",
        "    ],\n",
        "    [\n",
        "        [5,6,1000],\n",
        "        [7,8,2000],\n",
        "    ]\n",
        "])\n",
        "t5\n",
        "\n",
        "# It is not possible to create tensors with an improper shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220
        },
        "id": "m_p5xNptpbGv",
        "outputId": "bea20037-dfa0-42e3-b383-346758f0b004"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "expected sequence of length 2 at dim 2 (got 3)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-4995023bcf3c>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Matrix - 3D but improper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m t5 = torch.tensor([\n\u001b[0m\u001b[1;32m      4\u001b[0m     [\n\u001b[1;32m      5\u001b[0m        \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: expected sequence of length 2 at dim 2 (got 3)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PtURoB7IpbJx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tensors operations and gradients\n",
        "\n",
        "We can combine tensors with the usual arithmetic operations. Let's look at an example."
      ],
      "metadata": {
        "id": "mq-FKmDN_hRi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create tensors\n",
        "\n",
        "x = torch.tensor(5.)\n",
        "y = torch.tensor(10, requires_grad= True)\n",
        "z = torch.tensor(15, requires_grad= True)\n",
        "\n",
        "x, y, z"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220
        },
        "id": "cmXv4Z1bpbMg",
        "outputId": "69f6c054-f09d-47e8-8eea-c665a704604d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Only Tensors of floating point and complex dtype can require gradients",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-55edd44dcbc5>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Only Tensors of floating point and complex dtype can require gradients"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor(5.)\n",
        "y = torch.tensor(10., requires_grad= True)\n",
        "z = torch.tensor(15., requires_grad= True)\n",
        "\n",
        "# It means we can calculate derivatives of y and z but not x\n",
        "x, y, z"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8UrR4LLrpbPd",
        "outputId": "4c84446c-81be-44bc-9709-6c12de8a76ab"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(5.), tensor(10., requires_grad=True), tensor(15., requires_grad=True))"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.) Arithmetic operations\n"
      ],
      "metadata": {
        "id": "N3lzVAOcAcmS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = x * y + z\n",
        "a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n3xBlH7_pbVk",
        "outputId": "0252f8ec-ac17-4831-d188-e1cc31cb270a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(65., grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WY07mOM4pbYp"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.) Autograd(automic gradients)\n",
        "\n",
        "Note: What makes Pytorch unique is that we can automatically compute the derivative of \"z\" w.r.t. the tensors having ```requires_grad = True```, i.e. here y and z. This feature is called *Autograd*.\n",
        "\n",
        "To compute the derivatives, we can invoke the ```.backward``` method on our result \"a\"."
      ],
      "metadata": {
        "id": "G0LBlLUtA6jh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a.backward()"
      ],
      "metadata": {
        "id": "tKKklIFyEVeR"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "NOTE: The derivatives of a w.r.t. input tensors are stored in the ```.grad``` property of the respective tensors."
      ],
      "metadata": {
        "id": "4WWhYQ2oGX_i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v7rgKMoUErWL",
        "outputId": "66733723-950c-4bdf-f9a3-3725723b0a0e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(5.)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I8c_cKaUFa9h",
        "outputId": "6835b53c-b1ee-40d8-afdb-d6704deaad7f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute derivatives [a = x * y + z]\n",
        "\n",
        "print(\"da/dx\", x.grad)\n",
        "print(\"da/dy\", y.grad)      # x = 5\n",
        "print(\"da/dz\", z.grad)      # 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-rhjrSQXpbbY",
        "outputId": "9b76d18f-af4d-4bdd-c797-cdc50b589d77"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "da/dx None\n",
            "da/dy tensor(5.)\n",
            "da/dz tensor(1.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's differentatie once more.\n",
        "\n",
        "print(\"da/dx\", x.grad)\n",
        "print(\"da/dy\", y.grad)\n",
        "print(\"da/dz\", z.grad)\n",
        "\n",
        "# No change occured, same value"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oem2lBv9pbee",
        "outputId": "df51a4fe-c338-4efd-be91-b007f9b78a18"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "da/dx None\n",
            "da/dy tensor(5.)\n",
            "da/dz tensor(1.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Note:\n",
        "\n",
        "1. ```da/dy``` has the same value as ```x```, i.e. 5.\n",
        "\n",
        "2. ```da/dz``` has value as ```1```.\n",
        "\n",
        "3. ```da/dx``` is None because x doesn't have ```requires_set= True```\n",
        "\n",
        "The ```grad``` in y.grad is short for gradient, which is another term for gradient.\n",
        "\n",
        "The term gradient is primarily used while dealing with vectors and matrices."
      ],
      "metadata": {
        "id": "cjUDqSvLH0bp"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dZSMxt35pbhf"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tensor functions\n",
        "\n",
        "Apart from Arithmetic opeartions, the torch module also contains many functions for creating and manipulating tensors.\n",
        "\n",
        "Let's ook at some examples."
      ],
      "metadata": {
        "id": "3gUd1vkOJVV7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.) Tensor with fixed value for all element"
      ],
      "metadata": {
        "id": "STihLt4bJox5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t6 = torch.full((4,5), 8)\n",
        "t6"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ysrVDbIKpbkY",
        "outputId": "2f1e65ef-c0a7-42fe-c580-015ad5a3f192"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[8, 8, 8, 8, 8],\n",
              "        [8, 8, 8, 8, 8],\n",
              "        [8, 8, 8, 8, 8],\n",
              "        [8, 8, 8, 8, 8]])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t7 = torch.full((4,5), 0)\n",
        "t7"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qTFwL3wXpbn2",
        "outputId": "ac8e20af-3ec0-407a-c0a6-250a3aa1d74f"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XpVkiOJaJOog"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.) Concatanate 2 tensors with compatible shapes"
      ],
      "metadata": {
        "id": "bjn9ORHWRpM5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t8 = torch.cat((t6, t7))\n",
        "t8"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2yMr-rd6JOk4",
        "outputId": "babf3c65-cd30-4729-d88b-5a902d59fc07"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[8, 8, 8, 8, 8],\n",
              "        [8, 8, 8, 8, 8],\n",
              "        [8, 8, 8, 8, 8],\n",
              "        [8, 8, 8, 8, 8],\n",
              "        [0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RkInxTvLJOiN",
        "outputId": "dc3bf6a6-cc27-4b7e-f710-7df8b884f5c9"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  1,   2,   3, 100],\n",
              "        [  4,   5,   6, 200],\n",
              "        [  7,   8,   9, 300]])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t9 = torch.full((3,4), 2)\n",
        "t9"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eDoRltEJJOf3",
        "outputId": "6cde3953-d28f-41a9-fddf-3c51bff30fea"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2, 2, 2, 2],\n",
              "        [2, 2, 2, 2],\n",
              "        [2, 2, 2, 2]])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t10 = torch.cat((t3, t9))\n",
        "t10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "odREw3f6JOcz",
        "outputId": "8db1bc5e-88b1-458e-9d20-771bed361da7"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  1,   2,   3, 100],\n",
              "        [  4,   5,   6, 200],\n",
              "        [  7,   8,   9, 300],\n",
              "        [  2,   2,   2,   2],\n",
              "        [  2,   2,   2,   2],\n",
              "        [  2,   2,   2,   2]])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "I58X-aunTwxl"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.) Calculate the Sine of each element"
      ],
      "metadata": {
        "id": "ZorDt9ewUUeE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t11 = torch.sin(t10)\n",
        "t11"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L66MmSD-Tw0c",
        "outputId": "ea2cb67d-556f-4910-c41c-dcc18a57c879"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.8415,  0.9093,  0.1411, -0.5064],\n",
              "        [-0.7568, -0.9589, -0.2794, -0.8733],\n",
              "        [ 0.6570,  0.9894,  0.4121, -0.9998],\n",
              "        [ 0.9093,  0.9093,  0.9093,  0.9093],\n",
              "        [ 0.9093,  0.9093,  0.9093,  0.9093],\n",
              "        [ 0.9093,  0.9093,  0.9093,  0.9093]])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Lj2RqCdSTw3A"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.) Change the shape of tensor"
      ],
      "metadata": {
        "id": "boFhEiDIbmx9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t12 = t11.reshape(3, 2, 4)\n",
        "t12"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PJrm31pgTw52",
        "outputId": "caede818-a3aa-4108-9b2f-4e42ee68a300"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.8415,  0.9093,  0.1411, -0.5064],\n",
              "         [-0.7568, -0.9589, -0.2794, -0.8733]],\n",
              "\n",
              "        [[ 0.6570,  0.9894,  0.4121, -0.9998],\n",
              "         [ 0.9093,  0.9093,  0.9093,  0.9093]],\n",
              "\n",
              "        [[ 0.9093,  0.9093,  0.9093,  0.9093],\n",
              "         [ 0.9093,  0.9093,  0.9093,  0.9093]]])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "k5GS8ar-Tw8x"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Interoperability with Numpy\n",
        "\n",
        "Instead of reinventing the wheel, Pytorch interoperates well with Numpy to leverage its existing ecosystem of tools and libraries."
      ],
      "metadata": {
        "id": "ExOqC6TEca8i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an array in Numpy\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "x = np.array([ [1,2],[3,4] ])\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zFyVW58zTw_n",
        "outputId": "2cd54984-258f-4bf2-e0df-7ddc9af5958e"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 2],\n",
              "       [3, 4]])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NOTE:** We can convert a numpy array to a Pytorch tensor using ```torch.from_numpy(numpy_array_name)```.\n",
        "\n",
        "We can also convert back from tensor to numpy using ```.numpy(tensor_name)```"
      ],
      "metadata": {
        "id": "6Dm2FaF5dRJu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting a Numpy array to a torch tensor\n",
        "\n",
        "y = torch.from_numpy(x)\n",
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uS_ssQcWTxCj",
        "outputId": "14853acc-7f52-4987-df0d-de118e123c7b"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2],\n",
              "        [3, 4]])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.dtype, y.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Af5tsjcsTxGn",
        "outputId": "9a67f222-948e-4ed6-a385-a3f5d07508eb"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(dtype('int64'), torch.int64)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting a Tensor to a Numpy\n",
        "\n",
        "z = y.numpy()\n",
        "z"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wGA_bHXmTxKY",
        "outputId": "46a25370-c70a-45a4-a963-b957b81f889b"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 2],\n",
              "       [3, 4]])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EIvAOZqdeVzg"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Why Interoperability?\n",
        "\n",
        "- The interoperability between Numpy and Pytorch is essential because most datasets you'll work with likely be read and preprocessed as Numpy arrays.\n",
        "\n",
        "- You might wonder why we need a library like Pytorch at all since Numpy already provides data structures and utilities for working with multi-dimentional numeric data. There are 2 main reasons -\n",
        "\n",
        "1. **Autograd:** The ability to automatically compute gradients for tensor operations is essential for training depp learning models.\n",
        "\n",
        "2. **GPU Support:** While working with massive datasets and large models, Pytorch tensor operations can be performed efficiently using a GPU.\n",
        "\n",
        "- Computations that might typically take hours can be completed within minutes using GPUs."
      ],
      "metadata": {
        "id": "TIoXlexZfJo-"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gu_8sGPOeV2m"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Linear Regression from Scratch using Pytorch"
      ],
      "metadata": {
        "id": "ykbsvs7WUdOq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch"
      ],
      "metadata": {
        "id": "1PDYpe0h0Res"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Making trainign data\n",
        "# (temp, rainfall, humidity)\n",
        "\n",
        "INPUTS = np.array([\n",
        "    [70,60,42],\n",
        "    [90,50,40],\n",
        "    [87,134,58],\n",
        "    [100,43,37],\n",
        "    [69,96,70]],\n",
        "    dtype = 'float32')"
      ],
      "metadata": {
        "id": "KpHfwhjm0Rhg"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Targets -> (apples, oranges)\n",
        "TARGET = np.array([\n",
        "    [60, 70],\n",
        "    [50,40],\n",
        "    [134,58],\n",
        "    [43,37],\n",
        "    [96,70]],\n",
        "    dtype = 'float32')"
      ],
      "metadata": {
        "id": "yaz_btzr0Rkj"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert both I/P and O/P in \"tensors\"\n",
        "\n",
        "INPUT = torch.from_numpy(INPUTS)\n",
        "TARGET = torch.from_numpy(TARGET)\n",
        "\n",
        "print(\"inputs: \", INPUT)\n",
        "print(\"\\ntarget: \", TARGET)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Emh2TxAI0Rne",
        "outputId": "9d48c99f-6a29-4813-d755-f0f6b61e3263"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inputs:  tensor([[ 70.,  60.,  42.],\n",
            "        [ 90.,  50.,  40.],\n",
            "        [ 87., 134.,  58.],\n",
            "        [100.,  43.,  37.],\n",
            "        [ 69.,  96.,  70.]])\n",
            "\n",
            "target:  tensor([[ 60.,  70.],\n",
            "        [ 50.,  40.],\n",
            "        [134.,  58.],\n",
            "        [ 43.,  37.],\n",
            "        [ 96.,  70.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initiating Weights and Biases\n",
        "\n",
        "w = torch.randn(2,3 , requires_grad=True)\n",
        "b = torch.randn(2, requires_grad=True)\n",
        "\n",
        "print(\"Weight: \", w)\n",
        "print(\"\\nBiases: \", b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gbf-kRRJ0RqG",
        "outputId": "c3b812f8-ddc3-4171-c34b-a22a0bcf139a"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weight:  tensor([[ 1.3838, -2.4968,  0.8480],\n",
            "        [-0.7035,  0.1487,  1.2486]], requires_grad=True)\n",
            "\n",
            "Biases:  tensor([0.8560, 0.0715], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "boyjIhwK0Rtz"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#define the model\n",
        "\n",
        "def model(x):\n",
        "  return x @ w.t() + b"
      ],
      "metadata": {
        "id": "rR__68Ab0RxF"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NOTE: From here, I didn't heard lecture"
      ],
      "metadata": {
        "id": "_UhlacPQfP2K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prediction\n",
        "preds = model(INPUTS)\n",
        "print(preds)"
      ],
      "metadata": {
        "id": "umEnUrbdeV5i",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 274
        },
        "outputId": "36cd138b-f30e-4f2e-fb4b-403c7456458f"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "unsupported operand type(s) for @: 'numpy.ndarray' and 'Tensor'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-53-8c423835fa46>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mINPUTS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-51-621a77ceeecd>\u001b[0m in \u001b[0;36mmodel\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for @: 'numpy.ndarray' and 'Tensor'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(TARGET)"
      ],
      "metadata": {
        "id": "mVNrPZN8eV7_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92e27395-2251-4d04-ee97-2619132478ea"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 60.,  70.],\n",
            "        [ 50.,  40.],\n",
            "        [134.,  58.],\n",
            "        [ 43.,  37.],\n",
            "        [ 96.,  70.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss function MSE\n",
        "\n",
        "def MSE(actual, target):\n",
        "  diff = actual - target\n",
        "  return torch.sum(diff * diff) / diff.numel()\n",
        ""
      ],
      "metadata": {
        "id": "rZ9waB3XeV-s"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Error\n",
        "\n",
        "loss = MSE(TARGET, preds)\n",
        "print(\"loss: \", loss)"
      ],
      "metadata": {
        "id": "MDp5DlKNeWBS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "outputId": "2a865085-881e-4a95-9681-6d8a05b09b3d"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'preds' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-57-26bdf9eafe93>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMSE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTARGET\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loss: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'preds' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cg3Za8ZPJOaL"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute Gradients\n",
        "\n",
        "loss.backwards()"
      ],
      "metadata": {
        "id": "GQ1EjD3bJOXg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "outputId": "3d63ae25-68a2-4fac-d404-e2950b466770"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'loss' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-58-7b9f85bd9158>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Compute Gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackwards\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'loss' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"w: \", w, \"\\n\")\n",
        "print(\"w.grad: \", w.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c-usb2S9asUo",
        "outputId": "562703fd-c953-4403-a27e-060e2b008cdd"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "w:  tensor([[ 1.3838, -2.4968,  0.8480],\n",
            "        [-0.7035,  0.1487,  1.2486]], requires_grad=True) \n",
            "\n",
            "w.grad:  None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"b: \", b, \"\\n\")\n",
        "print(\"b.grad: \", b.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lUwdMSqeasXK",
        "outputId": "9bae0c58-cb1e-42ae-b5dd-0afcc28224ea"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b:  tensor([0.8560, 0.0715], requires_grad=True) \n",
            "\n",
            "b.grad:  None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reset grad\n",
        "\n",
        "w.grad.zero_()\n",
        "b.grad.zero_()\n",
        "\n",
        "print(w.grad)\n",
        "print(b.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220
        },
        "id": "36Y0PnbGasaD",
        "outputId": "4028f829-4503-4213-f492-9606da3ec2bb"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'NoneType' object has no attribute 'zero_'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-61-6cb9dee26ebc>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Reset grad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'zero_'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4pZMNkaOasc4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adjust parameters\n",
        "\n",
        "preds = model(INPUT)\n",
        "print(preds)\n",
        "\n",
        "loss = MSE(TARGET, preds)\n",
        "print(\"\\nLoss: \", loss)\n",
        "\n",
        "loss.backward()\n",
        "print(\"\\nw.grad:\", w.grad)\n",
        "print(\"\\nb.grad:\", b.grad)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AgwrJ8lNasfc",
        "outputId": "bb319b7a-f777-4618-f55b-49bd5e531007"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ -16.4715,   12.1895],\n",
            "        [  34.4764,   -5.8652],\n",
            "        [-164.1422,   31.2112],\n",
            "        [  63.2480,  -17.6872],\n",
            "        [ -83.9969,   53.2079]], grad_fn=<AddBackward0>)\n",
            "\n",
            "Loss:  tensor(13722.2441, grad_fn=<DivBackward0>)\n",
            "\n",
            "w.grad: tensor([[-25850.0859, -37034.7266, -19785.3574],\n",
            "        [-10279.5635,  -7989.1128,  -5409.1655]])\n",
            "\n",
            "b.grad: tensor([-329.9316, -121.1663])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sXAyej3bash6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adjust weight and reset grad\n",
        "with torch.no_grad():\n",
        "  w -= w.grad * 1e-5\n",
        "  b -= b.grad * 1e-5\n",
        "  w.grad.zero_()\n",
        "  b.grad.zero_()"
      ],
      "metadata": {
        "id": "StJW6t4Lasku"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(w)\n",
        "print(b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2wKoBKVYcHno",
        "outputId": "ab3ee23e-eebc-4e6d-ddcf-29ba1287f46a"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 1.6423, -2.1264,  1.0458],\n",
            "        [-0.6007,  0.2286,  1.3027]], requires_grad=True)\n",
            "tensor([0.8593, 0.0727], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate again\n",
        "\n",
        "preds = model(INPUT)\n",
        "loss = MSE(TARGET, preds)\n",
        "print(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zWD-DsUVcHqx",
        "outputId": "710d4a77-e6cc-4ded-dbe6-5dae04ea8792"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(6985.7822, grad_fn=<DivBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UkeipLIvcHtq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training for multiple epochs\n",
        "\n",
        "for i in range(400):\n",
        "  preds= model(INPUT)\n",
        "  loss = MSE(TARGET, preds)\n",
        "  loss.backward()\n",
        "\n",
        "  with torch.no_grad():\n",
        "    w -= w.grad * 1e-5\n",
        "    b -= b.grad * 1e-5\n",
        "    w.grad.zero_()\n",
        "    b.grad.zero_()\n",
        "  print(f\"Epochs({i}/{100}) & Loss: {loss}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qDqqcMaIcHwe",
        "outputId": "53514153-8cd9-4fda-cce4-4193bfff6909"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs(0/100) & Loss: 6985.7822265625\n",
            "Epochs(1/100) & Loss: 6192.0703125\n",
            "Epochs(2/100) & Loss: 5610.65625\n",
            "Epochs(3/100) & Loss: 5180.0078125\n",
            "Epochs(4/100) & Loss: 4856.5068359375\n",
            "Epochs(5/100) & Loss: 4609.2392578125\n",
            "Epochs(6/100) & Loss: 4416.28564453125\n",
            "Epochs(7/100) & Loss: 4262.1064453125\n",
            "Epochs(8/100) & Loss: 4135.685546875\n",
            "Epochs(9/100) & Loss: 4029.208251953125\n",
            "Epochs(10/100) & Loss: 3937.133544921875\n",
            "Epochs(11/100) & Loss: 3855.529296875\n",
            "Epochs(12/100) & Loss: 3781.604248046875\n",
            "Epochs(13/100) & Loss: 3713.37646484375\n",
            "Epochs(14/100) & Loss: 3649.436767578125\n",
            "Epochs(15/100) & Loss: 3588.78125\n",
            "Epochs(16/100) & Loss: 3530.69873046875\n",
            "Epochs(17/100) & Loss: 3474.67578125\n",
            "Epochs(18/100) & Loss: 3420.348388671875\n",
            "Epochs(19/100) & Loss: 3367.453125\n",
            "Epochs(20/100) & Loss: 3315.80078125\n",
            "Epochs(21/100) & Loss: 3265.252685546875\n",
            "Epochs(22/100) & Loss: 3215.70751953125\n",
            "Epochs(23/100) & Loss: 3167.090576171875\n",
            "Epochs(24/100) & Loss: 3119.34423828125\n",
            "Epochs(25/100) & Loss: 3072.425048828125\n",
            "Epochs(26/100) & Loss: 3026.298583984375\n",
            "Epochs(27/100) & Loss: 2980.936767578125\n",
            "Epochs(28/100) & Loss: 2936.317626953125\n",
            "Epochs(29/100) & Loss: 2892.421875\n",
            "Epochs(30/100) & Loss: 2849.23193359375\n",
            "Epochs(31/100) & Loss: 2806.73388671875\n",
            "Epochs(32/100) & Loss: 2764.91259765625\n",
            "Epochs(33/100) & Loss: 2723.75732421875\n",
            "Epochs(34/100) & Loss: 2683.254638671875\n",
            "Epochs(35/100) & Loss: 2643.39453125\n",
            "Epochs(36/100) & Loss: 2604.164794921875\n",
            "Epochs(37/100) & Loss: 2565.55517578125\n",
            "Epochs(38/100) & Loss: 2527.556884765625\n",
            "Epochs(39/100) & Loss: 2490.15771484375\n",
            "Epochs(40/100) & Loss: 2453.35009765625\n",
            "Epochs(41/100) & Loss: 2417.12353515625\n",
            "Epochs(42/100) & Loss: 2381.46875\n",
            "Epochs(43/100) & Loss: 2346.377197265625\n",
            "Epochs(44/100) & Loss: 2311.839111328125\n",
            "Epochs(45/100) & Loss: 2277.84619140625\n",
            "Epochs(46/100) & Loss: 2244.389892578125\n",
            "Epochs(47/100) & Loss: 2211.4609375\n",
            "Epochs(48/100) & Loss: 2179.05224609375\n",
            "Epochs(49/100) & Loss: 2147.15380859375\n",
            "Epochs(50/100) & Loss: 2115.7587890625\n",
            "Epochs(51/100) & Loss: 2084.859130859375\n",
            "Epochs(52/100) & Loss: 2054.44677734375\n",
            "Epochs(53/100) & Loss: 2024.5142822265625\n",
            "Epochs(54/100) & Loss: 1995.053466796875\n",
            "Epochs(55/100) & Loss: 1966.057373046875\n",
            "Epochs(56/100) & Loss: 1937.5181884765625\n",
            "Epochs(57/100) & Loss: 1909.428955078125\n",
            "Epochs(58/100) & Loss: 1881.7822265625\n",
            "Epochs(59/100) & Loss: 1854.5716552734375\n",
            "Epochs(60/100) & Loss: 1827.789794921875\n",
            "Epochs(61/100) & Loss: 1801.4300537109375\n",
            "Epochs(62/100) & Loss: 1775.485595703125\n",
            "Epochs(63/100) & Loss: 1749.9501953125\n",
            "Epochs(64/100) & Loss: 1724.8170166015625\n",
            "Epochs(65/100) & Loss: 1700.0794677734375\n",
            "Epochs(66/100) & Loss: 1675.7318115234375\n",
            "Epochs(67/100) & Loss: 1651.767333984375\n",
            "Epochs(68/100) & Loss: 1628.1807861328125\n",
            "Epochs(69/100) & Loss: 1604.965087890625\n",
            "Epochs(70/100) & Loss: 1582.115478515625\n",
            "Epochs(71/100) & Loss: 1559.6253662109375\n",
            "Epochs(72/100) & Loss: 1537.489501953125\n",
            "Epochs(73/100) & Loss: 1515.701904296875\n",
            "Epochs(74/100) & Loss: 1494.2569580078125\n",
            "Epochs(75/100) & Loss: 1473.150146484375\n",
            "Epochs(76/100) & Loss: 1452.3746337890625\n",
            "Epochs(77/100) & Loss: 1431.926513671875\n",
            "Epochs(78/100) & Loss: 1411.8001708984375\n",
            "Epochs(79/100) & Loss: 1391.9903564453125\n",
            "Epochs(80/100) & Loss: 1372.4920654296875\n",
            "Epochs(81/100) & Loss: 1353.3006591796875\n",
            "Epochs(82/100) & Loss: 1334.410888671875\n",
            "Epochs(83/100) & Loss: 1315.817626953125\n",
            "Epochs(84/100) & Loss: 1297.517578125\n",
            "Epochs(85/100) & Loss: 1279.504638671875\n",
            "Epochs(86/100) & Loss: 1261.7747802734375\n",
            "Epochs(87/100) & Loss: 1244.3238525390625\n",
            "Epochs(88/100) & Loss: 1227.1470947265625\n",
            "Epochs(89/100) & Loss: 1210.239990234375\n",
            "Epochs(90/100) & Loss: 1193.5987548828125\n",
            "Epochs(91/100) & Loss: 1177.21875\n",
            "Epochs(92/100) & Loss: 1161.095947265625\n",
            "Epochs(93/100) & Loss: 1145.2265625\n",
            "Epochs(94/100) & Loss: 1129.6060791015625\n",
            "Epochs(95/100) & Loss: 1114.2308349609375\n",
            "Epochs(96/100) & Loss: 1099.096923828125\n",
            "Epochs(97/100) & Loss: 1084.200927734375\n",
            "Epochs(98/100) & Loss: 1069.5380859375\n",
            "Epochs(99/100) & Loss: 1055.1055908203125\n",
            "Epochs(100/100) & Loss: 1040.899658203125\n",
            "Epochs(101/100) & Loss: 1026.916259765625\n",
            "Epochs(102/100) & Loss: 1013.15234375\n",
            "Epochs(103/100) & Loss: 999.6041259765625\n",
            "Epochs(104/100) & Loss: 986.2683715820312\n",
            "Epochs(105/100) & Loss: 973.1414794921875\n",
            "Epochs(106/100) & Loss: 960.220703125\n",
            "Epochs(107/100) & Loss: 947.5023193359375\n",
            "Epochs(108/100) & Loss: 934.9830322265625\n",
            "Epochs(109/100) & Loss: 922.6597900390625\n",
            "Epochs(110/100) & Loss: 910.5296630859375\n",
            "Epochs(111/100) & Loss: 898.58935546875\n",
            "Epochs(112/100) & Loss: 886.8362426757812\n",
            "Epochs(113/100) & Loss: 875.2667846679688\n",
            "Epochs(114/100) & Loss: 863.8787231445312\n",
            "Epochs(115/100) & Loss: 852.6686401367188\n",
            "Epochs(116/100) & Loss: 841.6339111328125\n",
            "Epochs(117/100) & Loss: 830.77197265625\n",
            "Epochs(118/100) & Loss: 820.0797729492188\n",
            "Epochs(119/100) & Loss: 809.554931640625\n",
            "Epochs(120/100) & Loss: 799.1943359375\n",
            "Epochs(121/100) & Loss: 788.9959716796875\n",
            "Epochs(122/100) & Loss: 778.95654296875\n",
            "Epochs(123/100) & Loss: 769.0741577148438\n",
            "Epochs(124/100) & Loss: 759.3462524414062\n",
            "Epochs(125/100) & Loss: 749.7701416015625\n",
            "Epochs(126/100) & Loss: 740.3436279296875\n",
            "Epochs(127/100) & Loss: 731.064208984375\n",
            "Epochs(128/100) & Loss: 721.9295654296875\n",
            "Epochs(129/100) & Loss: 712.9375\n",
            "Epochs(130/100) & Loss: 704.0855712890625\n",
            "Epochs(131/100) & Loss: 695.371826171875\n",
            "Epochs(132/100) & Loss: 686.7939453125\n",
            "Epochs(133/100) & Loss: 678.3497314453125\n",
            "Epochs(134/100) & Loss: 670.0371704101562\n",
            "Epochs(135/100) & Loss: 661.8539428710938\n",
            "Epochs(136/100) & Loss: 653.7982177734375\n",
            "Epochs(137/100) & Loss: 645.8679809570312\n",
            "Epochs(138/100) & Loss: 638.0612182617188\n",
            "Epochs(139/100) & Loss: 630.3760986328125\n",
            "Epochs(140/100) & Loss: 622.8101806640625\n",
            "Epochs(141/100) & Loss: 615.3622436523438\n",
            "Epochs(142/100) & Loss: 608.0301513671875\n",
            "Epochs(143/100) & Loss: 600.8118896484375\n",
            "Epochs(144/100) & Loss: 593.7059326171875\n",
            "Epochs(145/100) & Loss: 586.7103881835938\n",
            "Epochs(146/100) & Loss: 579.823486328125\n",
            "Epochs(147/100) & Loss: 573.0433959960938\n",
            "Epochs(148/100) & Loss: 566.3687744140625\n",
            "Epochs(149/100) & Loss: 559.7974853515625\n",
            "Epochs(150/100) & Loss: 553.3284301757812\n",
            "Epochs(151/100) & Loss: 546.9595947265625\n",
            "Epochs(152/100) & Loss: 540.6895141601562\n",
            "Epochs(153/100) & Loss: 534.5166015625\n",
            "Epochs(154/100) & Loss: 528.4393310546875\n",
            "Epochs(155/100) & Loss: 522.4562377929688\n",
            "Epochs(156/100) & Loss: 516.5657958984375\n",
            "Epochs(157/100) & Loss: 510.7666015625\n",
            "Epochs(158/100) & Loss: 505.0570373535156\n",
            "Epochs(159/100) & Loss: 499.43585205078125\n",
            "Epochs(160/100) & Loss: 493.9015197753906\n",
            "Epochs(161/100) & Loss: 488.45281982421875\n",
            "Epochs(162/100) & Loss: 483.08831787109375\n",
            "Epochs(163/100) & Loss: 477.806640625\n",
            "Epochs(164/100) & Loss: 472.60650634765625\n",
            "Epochs(165/100) & Loss: 467.4866638183594\n",
            "Epochs(166/100) & Loss: 462.44580078125\n",
            "Epochs(167/100) & Loss: 457.4827575683594\n",
            "Epochs(168/100) & Loss: 452.59613037109375\n",
            "Epochs(169/100) & Loss: 447.7850036621094\n",
            "Epochs(170/100) & Loss: 443.04791259765625\n",
            "Epochs(171/100) & Loss: 438.3836364746094\n",
            "Epochs(172/100) & Loss: 433.79132080078125\n",
            "Epochs(173/100) & Loss: 429.26959228515625\n",
            "Epochs(174/100) & Loss: 424.8172912597656\n",
            "Epochs(175/100) & Loss: 420.43353271484375\n",
            "Epochs(176/100) & Loss: 416.1172790527344\n",
            "Epochs(177/100) & Loss: 411.8670349121094\n",
            "Epochs(178/100) & Loss: 407.68231201171875\n",
            "Epochs(179/100) & Loss: 403.56158447265625\n",
            "Epochs(180/100) & Loss: 399.50421142578125\n",
            "Epochs(181/100) & Loss: 395.509033203125\n",
            "Epochs(182/100) & Loss: 391.5750427246094\n",
            "Epochs(183/100) & Loss: 387.7013854980469\n",
            "Epochs(184/100) & Loss: 383.88690185546875\n",
            "Epochs(185/100) & Loss: 380.130859375\n",
            "Epochs(186/100) & Loss: 376.4322204589844\n",
            "Epochs(187/100) & Loss: 372.7901306152344\n",
            "Epochs(188/100) & Loss: 369.2037658691406\n",
            "Epochs(189/100) & Loss: 365.67218017578125\n",
            "Epochs(190/100) & Loss: 362.1943664550781\n",
            "Epochs(191/100) & Loss: 358.7696228027344\n",
            "Epochs(192/100) & Loss: 355.39715576171875\n",
            "Epochs(193/100) & Loss: 352.07598876953125\n",
            "Epochs(194/100) & Loss: 348.80548095703125\n",
            "Epochs(195/100) & Loss: 345.5848083496094\n",
            "Epochs(196/100) & Loss: 342.4129638671875\n",
            "Epochs(197/100) & Loss: 339.2894592285156\n",
            "Epochs(198/100) & Loss: 336.21331787109375\n",
            "Epochs(199/100) & Loss: 333.1839599609375\n",
            "Epochs(200/100) & Loss: 330.2005920410156\n",
            "Epochs(201/100) & Loss: 327.2624206542969\n",
            "Epochs(202/100) & Loss: 324.3688049316406\n",
            "Epochs(203/100) & Loss: 321.5189208984375\n",
            "Epochs(204/100) & Loss: 318.71234130859375\n",
            "Epochs(205/100) & Loss: 315.9481506347656\n",
            "Epochs(206/100) & Loss: 313.2256774902344\n",
            "Epochs(207/100) & Loss: 310.54437255859375\n",
            "Epochs(208/100) & Loss: 307.9035339355469\n",
            "Epochs(209/100) & Loss: 305.3025817871094\n",
            "Epochs(210/100) & Loss: 302.7408752441406\n",
            "Epochs(211/100) & Loss: 300.2176818847656\n",
            "Epochs(212/100) & Loss: 297.73248291015625\n",
            "Epochs(213/100) & Loss: 295.28466796875\n",
            "Epochs(214/100) & Loss: 292.87371826171875\n",
            "Epochs(215/100) & Loss: 290.49884033203125\n",
            "Epochs(216/100) & Loss: 288.15972900390625\n",
            "Epochs(217/100) & Loss: 285.85565185546875\n",
            "Epochs(218/100) & Loss: 283.586181640625\n",
            "Epochs(219/100) & Loss: 281.3506164550781\n",
            "Epochs(220/100) & Loss: 279.14849853515625\n",
            "Epochs(221/100) & Loss: 276.9793395996094\n",
            "Epochs(222/100) & Loss: 274.8426208496094\n",
            "Epochs(223/100) & Loss: 272.73773193359375\n",
            "Epochs(224/100) & Loss: 270.66424560546875\n",
            "Epochs(225/100) & Loss: 268.6217346191406\n",
            "Epochs(226/100) & Loss: 266.60955810546875\n",
            "Epochs(227/100) & Loss: 264.6273193359375\n",
            "Epochs(228/100) & Loss: 262.67462158203125\n",
            "Epochs(229/100) & Loss: 260.7507629394531\n",
            "Epochs(230/100) & Loss: 258.8555603027344\n",
            "Epochs(231/100) & Loss: 256.98834228515625\n",
            "Epochs(232/100) & Loss: 255.14895629882812\n",
            "Epochs(233/100) & Loss: 253.33663940429688\n",
            "Epochs(234/100) & Loss: 251.55117797851562\n",
            "Epochs(235/100) & Loss: 249.79196166992188\n",
            "Epochs(236/100) & Loss: 248.0587921142578\n",
            "Epochs(237/100) & Loss: 246.3512420654297\n",
            "Epochs(238/100) & Loss: 244.66867065429688\n",
            "Epochs(239/100) & Loss: 243.0109405517578\n",
            "Epochs(240/100) & Loss: 241.3776397705078\n",
            "Epochs(241/100) & Loss: 239.76815795898438\n",
            "Epochs(242/100) & Loss: 238.1823272705078\n",
            "Epochs(243/100) & Loss: 236.61965942382812\n",
            "Epochs(244/100) & Loss: 235.0798797607422\n",
            "Epochs(245/100) & Loss: 233.56265258789062\n",
            "Epochs(246/100) & Loss: 232.06747436523438\n",
            "Epochs(247/100) & Loss: 230.59423828125\n",
            "Epochs(248/100) & Loss: 229.1424560546875\n",
            "Epochs(249/100) & Loss: 227.71170043945312\n",
            "Epochs(250/100) & Loss: 226.3016357421875\n",
            "Epochs(251/100) & Loss: 224.9121856689453\n",
            "Epochs(252/100) & Loss: 223.5428924560547\n",
            "Epochs(253/100) & Loss: 222.19332885742188\n",
            "Epochs(254/100) & Loss: 220.86331176757812\n",
            "Epochs(255/100) & Loss: 219.552490234375\n",
            "Epochs(256/100) & Loss: 218.2605438232422\n",
            "Epochs(257/100) & Loss: 216.9872283935547\n",
            "Epochs(258/100) & Loss: 215.7322998046875\n",
            "Epochs(259/100) & Loss: 214.49533081054688\n",
            "Epochs(260/100) & Loss: 213.27609252929688\n",
            "Epochs(261/100) & Loss: 212.07437133789062\n",
            "Epochs(262/100) & Loss: 210.88973999023438\n",
            "Epochs(263/100) & Loss: 209.72219848632812\n",
            "Epochs(264/100) & Loss: 208.5712127685547\n",
            "Epochs(265/100) & Loss: 207.43661499023438\n",
            "Epochs(266/100) & Loss: 206.3181610107422\n",
            "Epochs(267/100) & Loss: 205.21560668945312\n",
            "Epochs(268/100) & Loss: 204.12872314453125\n",
            "Epochs(269/100) & Loss: 203.05714416503906\n",
            "Epochs(270/100) & Loss: 202.0008087158203\n",
            "Epochs(271/100) & Loss: 200.95936584472656\n",
            "Epochs(272/100) & Loss: 199.9326629638672\n",
            "Epochs(273/100) & Loss: 198.9202880859375\n",
            "Epochs(274/100) & Loss: 197.9221649169922\n",
            "Epochs(275/100) & Loss: 196.9381561279297\n",
            "Epochs(276/100) & Loss: 195.96775817871094\n",
            "Epochs(277/100) & Loss: 195.01107788085938\n",
            "Epochs(278/100) & Loss: 194.06764221191406\n",
            "Epochs(279/100) & Loss: 193.13742065429688\n",
            "Epochs(280/100) & Loss: 192.22018432617188\n",
            "Epochs(281/100) & Loss: 191.31564331054688\n",
            "Epochs(282/100) & Loss: 190.42359924316406\n",
            "Epochs(283/100) & Loss: 189.54396057128906\n",
            "Epochs(284/100) & Loss: 188.67642211914062\n",
            "Epochs(285/100) & Loss: 187.82089233398438\n",
            "Epochs(286/100) & Loss: 186.97706604003906\n",
            "Epochs(287/100) & Loss: 186.14488220214844\n",
            "Epochs(288/100) & Loss: 185.32412719726562\n",
            "Epochs(289/100) & Loss: 184.51458740234375\n",
            "Epochs(290/100) & Loss: 183.71609497070312\n",
            "Epochs(291/100) & Loss: 182.92843627929688\n",
            "Epochs(292/100) & Loss: 182.15158081054688\n",
            "Epochs(293/100) & Loss: 181.38525390625\n",
            "Epochs(294/100) & Loss: 180.62930297851562\n",
            "Epochs(295/100) & Loss: 179.8835906982422\n",
            "Epochs(296/100) & Loss: 179.14791870117188\n",
            "Epochs(297/100) & Loss: 178.42214965820312\n",
            "Epochs(298/100) & Loss: 177.70616149902344\n",
            "Epochs(299/100) & Loss: 176.99977111816406\n",
            "Epochs(300/100) & Loss: 176.30282592773438\n",
            "Epochs(301/100) & Loss: 175.61517333984375\n",
            "Epochs(302/100) & Loss: 174.9366912841797\n",
            "Epochs(303/100) & Loss: 174.26718139648438\n",
            "Epochs(304/100) & Loss: 173.6066436767578\n",
            "Epochs(305/100) & Loss: 172.95477294921875\n",
            "Epochs(306/100) & Loss: 172.31155395507812\n",
            "Epochs(307/100) & Loss: 171.67678833007812\n",
            "Epochs(308/100) & Loss: 171.05030822753906\n",
            "Epochs(309/100) & Loss: 170.43209838867188\n",
            "Epochs(310/100) & Loss: 169.82191467285156\n",
            "Epochs(311/100) & Loss: 169.21975708007812\n",
            "Epochs(312/100) & Loss: 168.62539672851562\n",
            "Epochs(313/100) & Loss: 168.03872680664062\n",
            "Epochs(314/100) & Loss: 167.4596710205078\n",
            "Epochs(315/100) & Loss: 166.8881378173828\n",
            "Epochs(316/100) & Loss: 166.32386779785156\n",
            "Epochs(317/100) & Loss: 165.76695251464844\n",
            "Epochs(318/100) & Loss: 165.21707153320312\n",
            "Epochs(319/100) & Loss: 164.6742401123047\n",
            "Epochs(320/100) & Loss: 164.13833618164062\n",
            "Epochs(321/100) & Loss: 163.60922241210938\n",
            "Epochs(322/100) & Loss: 163.0868377685547\n",
            "Epochs(323/100) & Loss: 162.5710906982422\n",
            "Epochs(324/100) & Loss: 162.0618133544922\n",
            "Epochs(325/100) & Loss: 161.55886840820312\n",
            "Epochs(326/100) & Loss: 161.06224060058594\n",
            "Epochs(327/100) & Loss: 160.5718536376953\n",
            "Epochs(328/100) & Loss: 160.08758544921875\n",
            "Epochs(329/100) & Loss: 159.60928344726562\n",
            "Epochs(330/100) & Loss: 159.13693237304688\n",
            "Epochs(331/100) & Loss: 158.67044067382812\n",
            "Epochs(332/100) & Loss: 158.20956420898438\n",
            "Epochs(333/100) & Loss: 157.75448608398438\n",
            "Epochs(334/100) & Loss: 157.30484008789062\n",
            "Epochs(335/100) & Loss: 156.86074829101562\n",
            "Epochs(336/100) & Loss: 156.4219970703125\n",
            "Epochs(337/100) & Loss: 155.98866271972656\n",
            "Epochs(338/100) & Loss: 155.5604248046875\n",
            "Epochs(339/100) & Loss: 155.1374053955078\n",
            "Epochs(340/100) & Loss: 154.7194366455078\n",
            "Epochs(341/100) & Loss: 154.3064727783203\n",
            "Epochs(342/100) & Loss: 153.89840698242188\n",
            "Epochs(343/100) & Loss: 153.49520874023438\n",
            "Epochs(344/100) & Loss: 153.09677124023438\n",
            "Epochs(345/100) & Loss: 152.70301818847656\n",
            "Epochs(346/100) & Loss: 152.31390380859375\n",
            "Epochs(347/100) & Loss: 151.92935180664062\n",
            "Epochs(348/100) & Loss: 151.54920959472656\n",
            "Epochs(349/100) & Loss: 151.17355346679688\n",
            "Epochs(350/100) & Loss: 150.80223083496094\n",
            "Epochs(351/100) & Loss: 150.4351806640625\n",
            "Epochs(352/100) & Loss: 150.0723114013672\n",
            "Epochs(353/100) & Loss: 149.713623046875\n",
            "Epochs(354/100) & Loss: 149.35899353027344\n",
            "Epochs(355/100) & Loss: 149.0084228515625\n",
            "Epochs(356/100) & Loss: 148.6618194580078\n",
            "Epochs(357/100) & Loss: 148.31912231445312\n",
            "Epochs(358/100) & Loss: 147.98019409179688\n",
            "Epochs(359/100) & Loss: 147.64512634277344\n",
            "Epochs(360/100) & Loss: 147.31381225585938\n",
            "Epochs(361/100) & Loss: 146.9861297607422\n",
            "Epochs(362/100) & Loss: 146.66204833984375\n",
            "Epochs(363/100) & Loss: 146.34153747558594\n",
            "Epochs(364/100) & Loss: 146.02456665039062\n",
            "Epochs(365/100) & Loss: 145.71102905273438\n",
            "Epochs(366/100) & Loss: 145.40084838867188\n",
            "Epochs(367/100) & Loss: 145.09402465820312\n",
            "Epochs(368/100) & Loss: 144.79058837890625\n",
            "Epochs(369/100) & Loss: 144.49032592773438\n",
            "Epochs(370/100) & Loss: 144.19332885742188\n",
            "Epochs(371/100) & Loss: 143.89942932128906\n",
            "Epochs(372/100) & Loss: 143.60867309570312\n",
            "Epochs(373/100) & Loss: 143.32095336914062\n",
            "Epochs(374/100) & Loss: 143.0362091064453\n",
            "Epochs(375/100) & Loss: 142.75450134277344\n",
            "Epochs(376/100) & Loss: 142.47567749023438\n",
            "Epochs(377/100) & Loss: 142.1997833251953\n",
            "Epochs(378/100) & Loss: 141.9267120361328\n",
            "Epochs(379/100) & Loss: 141.65634155273438\n",
            "Epochs(380/100) & Loss: 141.38882446289062\n",
            "Epochs(381/100) & Loss: 141.12399291992188\n",
            "Epochs(382/100) & Loss: 140.8618621826172\n",
            "Epochs(383/100) & Loss: 140.602294921875\n",
            "Epochs(384/100) & Loss: 140.3453369140625\n",
            "Epochs(385/100) & Loss: 140.09091186523438\n",
            "Epochs(386/100) & Loss: 139.83905029296875\n",
            "Epochs(387/100) & Loss: 139.58970642089844\n",
            "Epochs(388/100) & Loss: 139.34271240234375\n",
            "Epochs(389/100) & Loss: 139.09817504882812\n",
            "Epochs(390/100) & Loss: 138.85597229003906\n",
            "Epochs(391/100) & Loss: 138.61618041992188\n",
            "Epochs(392/100) & Loss: 138.37863159179688\n",
            "Epochs(393/100) & Loss: 138.14334106445312\n",
            "Epochs(394/100) & Loss: 137.91024780273438\n",
            "Epochs(395/100) & Loss: 137.67942810058594\n",
            "Epochs(396/100) & Loss: 137.45079040527344\n",
            "Epochs(397/100) & Loss: 137.22421264648438\n",
            "Epochs(398/100) & Loss: 136.99977111816406\n",
            "Epochs(399/100) & Loss: 136.77737426757812\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds = model(INPUT)\n",
        "loss = MSE(TARGET, preds)\n",
        "print(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X6Z84dN3cHzG",
        "outputId": "8d5f63fe-292a-4cf8-aa45-3236c206d20a"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(136.5571, grad_fn=<DivBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from math import sqrt\n",
        "sqrt(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8dj6Nw8ucH1y",
        "outputId": "cde8bbf1-0a0e-44a9-8817-c37a76399c91"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11.685764122635833"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yzLoKaeLcH5P",
        "outputId": "4697a392-8576-4c6b-b437-54c109a9c750"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 64.1042,  46.4683],\n",
              "        [ 53.7314,  44.4190],\n",
              "        [114.2530,  59.7681],\n",
              "        [ 45.3772,  41.0406],\n",
              "        [112.4409,  78.7282]], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TARGET"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JJpXJehccIEA",
        "outputId": "01ca0a5a-f11b-48b4-e060-2dc7e18483ca"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 60.,  70.],\n",
              "        [ 50.,  40.],\n",
              "        [134.,  58.],\n",
              "        [ 43.,  37.],\n",
              "        [ 96.,  70.]])"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uMdrkWK9asna",
        "outputId": "c82e59cb-28ee-4f15-fb27-f1fa2ebe56ea"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 60.,  70.],\n",
              "       [ 50.,  40.],\n",
              "       [134.,  58.],\n",
              "       [ 43.,  37.],\n",
              "       [ 96.,  70.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## You can see they are almost close earch other"
      ],
      "metadata": {
        "id": "IqSiFrLHdmRl"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EWbyeuqbasp8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Neural Network using Pytorch"
      ],
      "metadata": {
        "id": "JswXHcrPdrsO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# To check GPU\n",
        "\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PHwqSVgUastY",
        "outputId": "46468334-cc37-4999-920a-30edd5e31d7c"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: nvidia-smi: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor, Lambda, Compose\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "y0cpOvBYdq7d"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download training data from open datasets.\n",
        "training_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        ")\n",
        "\n",
        "# Download test data from open datasets.\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z1vperssdq-O",
        "outputId": "d1b12d27-aad4-4d76-a881-2064a1e0adad"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26.4M/26.4M [00:01<00:00, 17.9MB/s]\n",
            "100%|██████████| 29.5k/29.5k [00:00<00:00, 273kB/s]\n",
            "100%|██████████| 4.42M/4.42M [00:00<00:00, 4.89MB/s]\n",
            "100%|██████████| 5.15k/5.15k [00:00<00:00, 8.08MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(training_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "5kYpe3d-drA-",
        "outputId": "1f9aa459-bc82-4e52-b90f-f824162806e6"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torchvision.datasets.mnist.FashionMNIST"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>torchvision.datasets.mnist.FashionMNIST</b><br/>def __init__(root: Union[str, Path], train: bool=True, transform: Optional[Callable]=None, target_transform: Optional[Callable]=None, download: bool=False) -&gt; None</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.11/dist-packages/torchvision/datasets/mnist.py</a>`Fashion-MNIST &lt;https://github.com/zalandoresearch/fashion-mnist&gt;`_ Dataset.\n",
              "\n",
              "Args:\n",
              "    root (str or ``pathlib.Path``): Root directory of dataset where ``FashionMNIST/raw/train-images-idx3-ubyte``\n",
              "        and  ``FashionMNIST/raw/t10k-images-idx3-ubyte`` exist.\n",
              "    train (bool, optional): If True, creates dataset from ``train-images-idx3-ubyte``,\n",
              "        otherwise from ``t10k-images-idx3-ubyte``.\n",
              "    download (bool, optional): If True, downloads the dataset from the internet and\n",
              "        puts it in root directory. If dataset is already downloaded, it is not\n",
              "        downloaded again.\n",
              "    transform (callable, optional): A function/transform that  takes in a PIL image\n",
              "        and returns a transformed version. E.g, ``transforms.RandomCrop``\n",
              "    target_transform (callable, optional): A function/transform that takes in the\n",
              "        target and transforms it.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 204);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "\n",
        "# Create data loaders.\n",
        "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
        "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
        "\n",
        "for X, y in test_dataloader:\n",
        "    print(\"Shape of X [N, C, H, W]: \", X.shape)\n",
        "    print(\"Shape of y: \", y.shape, y.dtype)\n",
        "    # print(X)\n",
        "    # print(y)\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kzrpjdJSdrDd",
        "outputId": "c138a281-9f22-46cc-971f-a99b7e5730fa"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X [N, C, H, W]:  torch.Size([64, 1, 28, 28])\n",
            "Shape of y:  torch.Size([64]) torch.int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get cpu or gpu device for training.\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using {device} device\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gPfTJKpLdrHO",
        "outputId": "56b1bdcb-8fad-4829-a534-1f06edff1d21"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define model\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(28*28, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits\n",
        "\n",
        "model = NeuralNetwork().to(device)\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0KiJ3UqudrJy",
        "outputId": "cf853fee-3384-4efd-d892-550788b2b5bc"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NeuralNetwork(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
      ],
      "metadata": {
        "id": "vnu5eEQJdrMJ"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.train()\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        # Compute prediction error\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), batch * len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
      ],
      "metadata": {
        "id": "8iTJIyDvdrP1"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(dataloader, model, loss_fn):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    model.eval()\n",
        "    test_loss, correct = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
      ],
      "metadata": {
        "id": "fxV_veqVas3N"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 5\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train(train_dataloader, model, loss_fn, optimizer)\n",
        "    test(test_dataloader, model, loss_fn)\n",
        "print(\"Done!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ntAAT4Wredwv",
        "outputId": "d95bd86e-cc07-4310-8c36-2bb232427e2a"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 2.303740  [    0/60000]\n",
            "loss: 2.294145  [ 6400/60000]\n",
            "loss: 2.266220  [12800/60000]\n",
            "loss: 2.266222  [19200/60000]\n",
            "loss: 2.256898  [25600/60000]\n",
            "loss: 2.208330  [32000/60000]\n",
            "loss: 2.231146  [38400/60000]\n",
            "loss: 2.184168  [44800/60000]\n",
            "loss: 2.185485  [51200/60000]\n",
            "loss: 2.159570  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 42.4%, Avg loss: 2.151335 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 2.153939  [    0/60000]\n",
            "loss: 2.150010  [ 6400/60000]\n",
            "loss: 2.088743  [12800/60000]\n",
            "loss: 2.116952  [19200/60000]\n",
            "loss: 2.060699  [25600/60000]\n",
            "loss: 1.990301  [32000/60000]\n",
            "loss: 2.032094  [38400/60000]\n",
            "loss: 1.941968  [44800/60000]\n",
            "loss: 1.955834  [51200/60000]\n",
            "loss: 1.890530  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 53.7%, Avg loss: 1.883492 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 1.906819  [    0/60000]\n",
            "loss: 1.884526  [ 6400/60000]\n",
            "loss: 1.768864  [12800/60000]\n",
            "loss: 1.819063  [19200/60000]\n",
            "loss: 1.697651  [25600/60000]\n",
            "loss: 1.649017  [32000/60000]\n",
            "loss: 1.675237  [38400/60000]\n",
            "loss: 1.572607  [44800/60000]\n",
            "loss: 1.606764  [51200/60000]\n",
            "loss: 1.504372  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 59.1%, Avg loss: 1.518531 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 1.578671  [    0/60000]\n",
            "loss: 1.549753  [ 6400/60000]\n",
            "loss: 1.406310  [12800/60000]\n",
            "loss: 1.476491  [19200/60000]\n",
            "loss: 1.350803  [25600/60000]\n",
            "loss: 1.350927  [32000/60000]\n",
            "loss: 1.360180  [38400/60000]\n",
            "loss: 1.285564  [44800/60000]\n",
            "loss: 1.326946  [51200/60000]\n",
            "loss: 1.227512  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 63.0%, Avg loss: 1.252501 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 1.324287  [    0/60000]\n",
            "loss: 1.310572  [ 6400/60000]\n",
            "loss: 1.152677  [12800/60000]\n",
            "loss: 1.252397  [19200/60000]\n",
            "loss: 1.123635  [25600/60000]\n",
            "loss: 1.154498  [32000/60000]\n",
            "loss: 1.168490  [38400/60000]\n",
            "loss: 1.106521  [44800/60000]\n",
            "loss: 1.152608  [51200/60000]\n",
            "loss: 1.067026  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 64.6%, Avg loss: 1.087647 \n",
            "\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZXPoNLlgefwL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#save model\n",
        "torch.save(model.state_dict(), \"model.pth\")\n",
        "print(\"Saved PyTorch Model State to model.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0FyOwWoOek7w",
        "outputId": "d242fe2d-2975-4587-ee9e-cc324af16b9c"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved PyTorch Model State to model.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#load model\n",
        "model = NeuralNetwork()\n",
        "model.load_state_dict(torch.load(\"model.pth\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kpoqtifpek-u",
        "outputId": "e77b7da1-f1b3-46ca-eed1-ce446e8e1d0f"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Prediction\n",
        "\n",
        "classes = [\n",
        "    \"T-shirt/top\",\n",
        "    \"Trouser\",\n",
        "    \"Pullover\",\n",
        "    \"Dress\",\n",
        "    \"Coat\",\n",
        "    \"Sandal\",\n",
        "    \"Shirt\",\n",
        "    \"Sneaker\",\n",
        "    \"Bag\",\n",
        "    \"Ankle boot\",\n",
        "]\n",
        "\n",
        "model.eval()\n",
        "x, y = test_data[0][0], test_data[0][1]\n",
        "with torch.no_grad():\n",
        "    pred = model(x)\n",
        "    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
        "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nsu1OHCLelBx",
        "outputId": "777c624c-b395-4d8a-ce66-be02120749f9"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted: \"Ankle boot\", Actual: \"Ankle boot\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7Oc30CU9elEZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "syjMJJzPelHL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NQrzf8paelKP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ho9CQ_byelNu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}